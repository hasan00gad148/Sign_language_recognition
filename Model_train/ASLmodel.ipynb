{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQWWJGAoeoyO",
        "outputId": "4dc83e0e-7872-4dab-c249-831a11a14efa"
      },
      "outputs": [],
      "source": [
        "# !pip install patool\n",
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S90SBuqVd2lN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, ReLU, Dropout, GRU, ConvLSTM2D, Conv3D, Flatten, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random \n",
        "from sklearn.model_selection import train_test_split\n",
        "import mediapipe as mp\n",
        "# import pickle as pk\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FySGWtTcekwc",
        "outputId": "8c684830-b413-4252-c1f4-d04cf3be10a6"
      },
      "outputs": [],
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "%cd drive/MyDrive/Colab Notebooks/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5KSV52feVCk"
      },
      "outputs": [],
      "source": [
        "# import patoolib\n",
        "# patoolib.extract_archive(path, outdir=\"./\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnkdAmeTd2lT"
      },
      "outputs": [],
      "source": [
        "mp_holistic = mp.solutions.holistic # Holistic model\n",
        "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv_JGDvxd2lU"
      },
      "outputs": [],
      "source": [
        "holistic = mp_holistic.Holistic(\n",
        "    static_image_mode=True,\n",
        "    model_complexity=1,\n",
        "    enable_segmentation=False,\n",
        "    refine_face_landmarks=False,\n",
        "    min_detection_confidence=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5_71eH1d2lU"
      },
      "outputs": [],
      "source": [
        "def mediapipe_detection(image, model):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
        "    image.flags.writeable = False                  # Image is no longer writeable\n",
        "    results = model.process(image)                 # Make prediction\n",
        "    image.flags.writeable = True                   # Image is now writeable \n",
        "    return  results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uazSen9td2lW"
      },
      "outputs": [],
      "source": [
        "def normalize_norm(pose, face, lh, rh):\n",
        "    \n",
        "    \n",
        "    norm = np.sum(pose**2, axis=-1)**(1./2) + 1e-7\n",
        "    tmp = pose.T/norm\n",
        "    pose = tmp.T\n",
        "    \n",
        "    norm = np.sum(face**2, axis=-1)**(1./2) + 1e-7\n",
        "    tmp = face.T/norm\n",
        "    face = tmp.T\n",
        "    \n",
        "    norm = np.sum(lh**2, axis=-1)**(1./2) + 1e-7\n",
        "    tmp = lh.T/norm\n",
        "    lh = tmp.T\n",
        "    \n",
        "    norm = np.sum(rh**2, axis=-1)**(1./2) + 1e-7\n",
        "    tmp = rh.T/norm\n",
        "    rh = tmp.T\n",
        "    return pose, face, lh, rh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHaK61Ljd2lV"
      },
      "outputs": [],
      "source": [
        "def normalize_zscore(pose, face, lh, rh):\n",
        "       \n",
        "    m = pose.mean(axis=0)\n",
        "    std  = pose.std(axis=0) + 1e-7\n",
        "    pose = (pose - m)/std\n",
        "    \n",
        "    # print(pose.shape,m.shape,std.shape)\n",
        "    \n",
        "    m = face.mean(axis=0)\n",
        "    std  = face.std(axis=0) + 1e-7\n",
        "    face = (face - m)/std\n",
        "    \n",
        "    m = lh.mean(axis=0)\n",
        "    std  = lh.std(axis=0) + 1e-7\n",
        "    lh = (lh - m)/std\n",
        "    \n",
        "    m = rh.mean(axis=0)\n",
        "    std  = rh.std(axis=0) + 1e-7\n",
        "    rh = (rh - m)/std\n",
        "    \n",
        "    return pose, face, lh, rh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg6MW6m0d2lW"
      },
      "outputs": [],
      "source": [
        "def extract_keypoints(results):\n",
        "\n",
        "    pose = np.array([[res.x, res.y,res.z] for res in results.pose_landmarks.landmark]) if results.pose_landmarks else np.zeros(33*3)\n",
        "    face = np.array([[res.x, res.y,res.z] for res in results.face_landmarks.landmark]) if results.face_landmarks else np.zeros(468*3)\n",
        "    lh = np.array([[res.x, res.y,res.z] for res in results.left_hand_landmarks.landmark]) if results.left_hand_landmarks else np.zeros(21*3)\n",
        "    rh = np.array([[res.x, res.y,res.z] for res in results.right_hand_landmarks.landmark]) if results.right_hand_landmarks else np.zeros(21*3)\n",
        "\n",
        "    pose, face, lh, rh = normalize_zscore(pose, face, lh, rh)\n",
        "\n",
        "    return np.concatenate([pose.flatten(), face.flatten(), lh.flatten(), rh.flatten()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ucnbCs_d2lX"
      },
      "outputs": [],
      "source": [
        "def draw_styled_landmarks(image, results):\n",
        "    # Draw face connections\n",
        "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
        "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
        "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
        "                             ) \n",
        "    # Draw pose connections\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
        "                             ) \n",
        "    # Draw left hand connections\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
        "                             ) \n",
        "    # Draw right hand connections  \n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
        "                             ) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqMeVlA4a0qv"
      },
      "source": [
        "***\n",
        "***\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv9tRo60d2lY"
      },
      "outputs": [],
      "source": [
        "path =\"./traindata/all\"\n",
        "file_list = os.listdir(path)\n",
        "files = file_list\n",
        "files.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZtcUPkMd2lY",
        "outputId": "790c9ce4-d629-49b3-ae9b-09e08a5802dc"
      },
      "outputs": [],
      "source": [
        "len(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w15lPLu1d2lZ",
        "outputId": "cbcb3d2b-9e52-493c-b0c7-73d9b9bdd028"
      },
      "outputs": [],
      "source": [
        "files = [path+\"/\"+f for f in files]# \n",
        "files[0],files[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TBcFTJLd2lZ"
      },
      "outputs": [],
      "source": [
        "def videoProc(path, c=1,skip=5, o=False):\n",
        "    \"###\"\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    success = True\n",
        "    \n",
        "    framecount = 35\n",
        "\n",
        "    fnum = 0\n",
        "    v = []\n",
        "    \n",
        "    fpsCounter = c\n",
        "\n",
        "    for i in range(skip):\n",
        "        success, frame = cap.read()\n",
        "\n",
        "    while success:     \n",
        "        success, frame = cap.read()\n",
        "        \n",
        "        if fpsCounter==0:\n",
        "            fpsCounter=c\n",
        "        else:\n",
        "            fpsCounter-=1           \n",
        "            continue\n",
        "        if fnum>=framecount:\n",
        "            break\n",
        "\n",
        "        \n",
        "        if success:  \n",
        "            # frame = cv2.resize(frame, (1920,1080), interpolation = cv2.INTER_AREA)\n",
        "            results = mediapipe_detection(frame, holistic)\n",
        "\n",
        "            eres = extract_keypoints(results)\n",
        "            tmp = np.reshape(eres, (1,-1))\n",
        "            v.append(tmp)\n",
        "\n",
        "            fnum += 1\n",
        "            if o:\n",
        "                draw_styled_landmarks(frame, results)\n",
        "                plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "    v = np.reshape(v,(fnum,-1)) if fnum >0 else[]\n",
        "    \n",
        "  \n",
        "    if fnum<framecount and fnum>0:\n",
        "        tmp = np.zeros((framecount-fnum,1629))\n",
        "        v = np.concatenate((v, tmp), axis=0) \n",
        "\n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKzqJ4Bgd2la",
        "outputId": "07672b31-eb21-456d-a116-30c589a65692"
      },
      "outputs": [],
      "source": [
        "v= videoProc(files[256],c=2,o=0)\n",
        "v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4mWhWrRd2la",
        "outputId": "07c402bb-6a11-4b3f-d392-70242d3e0ef5"
      },
      "outputs": [],
      "source": [
        "v[34].max(),v[29].min(),v[24].std(),v[24].mean()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "ZUfBS7LWd2lb"
      },
      "source": [
        "s=0\n",
        "for i in range(400,800,5):\n",
        "    v = videoProc(files[i],c=1)\n",
        "    print(i,v.shape[0])\n",
        "    s+=v.shape[0]\n",
        "s/42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsEY286Wd2lc"
      },
      "outputs": [],
      "source": [
        "l=0\n",
        "vids = []\n",
        "labels = []\n",
        "files_ = files[2200:3200]\n",
        "for f in files_:\n",
        "    v = videoProc(f,c=2)\n",
        "    vids.append(v)\n",
        "    label = f.split('/')[-1].split('_')[0] \n",
        "    labels.append(label)\n",
        "    print(l)\n",
        "    l+=1\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp8h7MPNd2ld"
      },
      "outputs": [],
      "source": [
        "labels = [int(l)-1 for l in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGTAoC0Ad2le"
      },
      "outputs": [],
      "source": [
        "vids = np.array(vids)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcnBGDfAd2le",
        "outputId": "61bc539a-f5df-4753-abe8-a28ece543999"
      },
      "outputs": [],
      "source": [
        "labels.shape,vids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz0ntSFOd2le"
      },
      "outputs": [],
      "source": [
        "np.save(\"./vids_3.npy\",vids)\n",
        "np.save(\"./labels_3.npy\",labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2JySTKVa81H"
      },
      "source": [
        "***\n",
        "***\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_oz21sVd2lf"
      },
      "outputs": [],
      "source": [
        "vids1 = np.load(\"./traindata/vids_1.npy\")\n",
        "labels1 = np.load(\"./traindata//labels_1.npy\")\n",
        "\n",
        "vids2 = np.load(\"./traindata//vids_2.npy\")\n",
        "labels2 = np.load(\"./traindata//labels_2.npy\")\n",
        "\n",
        "vids3 = np.load(\"./traindata//vids_3.npy\")\n",
        "labels3 = np.load(\"./traindata//labels_3.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTvbkwpDAOUp"
      },
      "outputs": [],
      "source": [
        "vids = np.concatenate([vids1,vids2,vids3],axis=0)\n",
        "labels = np.concatenate([labels1,labels2,labels3],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkhm91HY47M1",
        "outputId": "8533c7b9-e0f1-4349-be27-e225b03ca039"
      },
      "outputs": [],
      "source": [
        "vids.shape,labels.shape,labels.min(),labels.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92DkAco-d2lf",
        "outputId": "536189fb-5456-4d6e-cb45-c79f6041ac02"
      },
      "outputs": [],
      "source": [
        "X_train, X_dev, y_train, y_dev = train_test_split(vids, labels, test_size = 0.15,shuffle=True,random_state=13)\n",
        "X_train.shape,y_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5PqiZQDm0jf"
      },
      "outputs": [],
      "source": [
        "del vids\n",
        "del labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfAVTKlrd2lg",
        "outputId": "b2bf6d50-359e-4488-d547-4e13b36c78b3"
      },
      "outputs": [],
      "source": [
        "X_train[3].min(),X_train[3].max(),X_train[3].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HNPMiUud2lg",
        "outputId": "10a066b8-c0d9-4707-b9ea-b8564ea6dc4b"
      },
      "outputs": [],
      "source": [
        "y_train[0:10],y_train.min(),y_train.max(),y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7q9lb73d2lh"
      },
      "outputs": [],
      "source": [
        "model_lstm_1 = Sequential([\n",
        "\n",
        "tf.keras.Input(shape=(35,1629),),\n",
        "    \n",
        "LSTM(64, return_sequences=True, activation='tanh'),\n",
        "Dropout(0.2),\n",
        "LSTM(128, return_sequences=True, activation='tanh'),\n",
        "Dropout(0.2),\n",
        "LSTM(256, return_sequences=False, activation='tanh'),\n",
        "\n",
        "# Bidirectional(GRU(64, return_sequences=True, activation='tanh')),\n",
        "# Bidirectional(GRU(256, return_sequences=True, activation='tanh')),\n",
        "# Bidirectional(GRU(128, return_sequences=False, activation='tanh')),\n",
        "\n",
        "\n",
        "BatchNormalization(),\n",
        "Dropout(0.4),\n",
        "\n",
        "\n",
        "\n",
        "Dense(256, activation='linear',kernel_regularizer=tf.keras.regularizers.L1L2(0.01,1)),  \n",
        "BatchNormalization(),#axis=-1,center=True,scale=True,\n",
        "ReLU(), \n",
        "\n",
        "Dense(128, activation='linear',kernel_regularizer=tf.keras.regularizers.L1L2(0.01,1)),  \n",
        "BatchNormalization(),#axis=-1,center=True,scale=True,\n",
        "ReLU(), \n",
        "\n",
        "\n",
        "Dense(64, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkM404Fad2lh",
        "outputId": "4b1c2228-a438-40be-dee5-8199c4773c53"
      },
      "outputs": [],
      "source": [
        "model_lstm_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2K4MECAd2lh"
      },
      "outputs": [],
      "source": [
        "model_lstm_1.compile(tf.keras.optimizers.Adam(learning_rate=1e-3,beta_1=0.9,beta_2=0.999,epsilon=1e-07,)\n",
        "        ,loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "            ,metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrJXaEhld2li",
        "outputId": "48243e41-d172-466a-d985-f7ad2ea6d28a"
      },
      "outputs": [],
      "source": [
        "model_lstm_1.fit(X_train, y_train, epochs=256, batch_size=128, )#batch_size=64 ,#validation_data=(X_dev, y_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q-Ll2P0d2li"
      },
      "outputs": [],
      "source": [
        "model_lstm_1.compile(tf.keras.optimizers.Adam(learning_rate=1e-4,beta_1=0.9,beta_2=0.999,epsilon=1e-07,)\n",
        "        ,loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "            ,metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvaovqJfd2lj",
        "outputId": "73cd5328-b81b-4993-8474-df96cdee6d83"
      },
      "outputs": [],
      "source": [
        "model_lstm_1.fit(X_train, y_train, epochs=128, batch_size=128,)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "WjpvX_x2d2lj"
      },
      "source": [
        "reconstructed_model = tf.keras.models.load_model(\"./modelArgantine/v6\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn7BhRLnd2lj",
        "outputId": "0da6cd48-0880-441b-ae9d-507704b8b40a"
      },
      "outputs": [],
      "source": [
        "model_lstm_1.evaluate(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8In9OzFfd2lj",
        "outputId": "8767f818-0430-4f92-d573-06acaa1d6f1e"
      },
      "outputs": [],
      "source": [
        "model_lstm_1.evaluate(X_dev, y_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XtJXHhkd2lk",
        "outputId": "52a4198b-1fdc-4d79-ee32-6b4296252cff"
      },
      "outputs": [],
      "source": [
        "model_lstm_1.save(\"./modelArgantine/v0_1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA6r8PfPd2lk"
      },
      "outputs": [],
      "source": [
        "def videoProc2(path, c=1, skip=0, o=False):\n",
        "    \"###\"\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    success = True\n",
        "    \n",
        "    framecount = 35\n",
        "\n",
        "    fnum = 0\n",
        "    v = []\n",
        "    \n",
        "    fpsCounter = c\n",
        "\n",
        "\n",
        "    while success:     \n",
        "        success, frame = cap.read()\n",
        "        \n",
        "        if fpsCounter==0:\n",
        "            fpsCounter=c\n",
        "        else:\n",
        "            fpsCounter-=1           \n",
        "            continue\n",
        "        \n",
        "        \n",
        "        if success:  \n",
        "            frame = cv2.resize(frame, (1920,1080), interpolation = cv2.INTER_AREA)\n",
        "            results = mediapipe_detection(frame, holistic)\n",
        "\n",
        "            eres = extract_keypoints(results)\n",
        "            tmp = np.reshape(eres, (1,-1))\n",
        "            v.append(tmp)\n",
        "\n",
        "            fnum += 1\n",
        "            if o:\n",
        "                draw_styled_landmarks(frame, results)\n",
        "                plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "    v = np.reshape(v,(fnum,-1)) if fnum >0 else[]\n",
        "\n",
        "\n",
        "    if fnum > framecount+skip:\n",
        "        # f = int((fnum>framecount)/2)\n",
        "        v = v[skip:framecount+skip]\n",
        "    else:  v[0:framecount]\n",
        "        \n",
        "    if fnum<framecount and fnum>0:\n",
        "        tmp = np.zeros((framecount-fnum,1629))\n",
        "        v = np.concatenate((v, tmp), axis=0) \n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxEiRuJBfEyg",
        "outputId": "3c1bb538-c7f1-4b05-f805-f453ac2272f1"
      },
      "outputs": [],
      "source": [
        "path =\"./traindata/all\"\n",
        "file_list = os.listdir(path)\n",
        "files = file_list\n",
        "files.sort()\n",
        "files = [path+\"/\"+f for f in files]# \n",
        "files[0],files[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IWymHZNd2lk",
        "outputId": "013508e8-1fa3-4981-c3c7-cf6a6b55f481"
      },
      "outputs": [],
      "source": [
        "v = videoProc2(files[512],c=0,skip=8,o=0)#files[123]\n",
        "v[34].max(),v[29].max(),v[24].max(),v[15].max(),v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kizl2IsLd2ll",
        "outputId": "51c6a582-b783-4a46-f386-259d9bebe82c"
      },
      "outputs": [],
      "source": [
        "p=model_lstm_1.predict(np.reshape(v, (1,35,1629)))\n",
        "np.argmax(p),p\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXiZe7ONgdvg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yb4EBVmageB4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a8e62510b8e8983f7396e073327258ed7f98a07d0a71789f266ad6c411666256"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
