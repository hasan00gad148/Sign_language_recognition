{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install patool\n",
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQWWJGAoeoyO",
        "outputId": "4dc83e0e-7872-4dab-c249-831a11a14efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.9.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (22.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (23.1.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.5.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.8/dist-packages (from mediapipe) (4.6.0.66)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.8/dist-packages (from mediapipe) (3.19.6)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (4.38.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.15.0)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.9.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S90SBuqVd2lN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, ReLU, Dropout, GRU, ConvLSTM2D, Conv3D, Flatten, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random \n",
        "from sklearn.model_selection import train_test_split\n",
        "import mediapipe as mp\n",
        "# import pickle as pk\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "%cd drive/MyDrive/Colab Notebooks/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FySGWtTcekwc",
        "outputId": "8c684830-b413-4252-c1f4-d04cf3be10a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import patoolib\n",
        "# patoolib.extract_archive(path, outdir=\"./\")"
      ],
      "metadata": {
        "id": "N5KSV52feVCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnkdAmeTd2lT"
      },
      "outputs": [],
      "source": [
        "mp_holistic = mp.solutions.holistic # Holistic model\n",
        "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv_JGDvxd2lU"
      },
      "outputs": [],
      "source": [
        "holistic = mp_holistic.Holistic(\n",
        "    static_image_mode=True,\n",
        "    model_complexity=1,\n",
        "    enable_segmentation=False,\n",
        "    refine_face_landmarks=False,\n",
        "    min_detection_confidence=0.4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5_71eH1d2lU"
      },
      "outputs": [],
      "source": [
        "def mediapipe_detection(image, model):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
        "    image.flags.writeable = False                  # Image is no longer writeable\n",
        "    results = model.process(image)                 # Make prediction\n",
        "    image.flags.writeable = True                   # Image is now writeable \n",
        "    return  results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uazSen9td2lW"
      },
      "outputs": [],
      "source": [
        "def normalize_norm(pose, face, lh, rh):\n",
        "    \n",
        "    \n",
        "    norm = np.sum(pose**2, axis=-1)**(1./2) + 1e-7\n",
        "    tmp = pose.T/norm\n",
        "    pose = tmp.T\n",
        "    \n",
        "    norm = np.sum(face**2, axis=-1)**(1./2) + 1e-7\n",
        "    tmp = face.T/norm\n",
        "    face = tmp.T\n",
        "    \n",
        "    norm = np.sum(lh**2, axis=-1)**(1./2) + 1e-7\n",
        "    tmp = lh.T/norm\n",
        "    lh = tmp.T\n",
        "    \n",
        "    norm = np.sum(rh**2, axis=-1)**(1./2) + 1e-7\n",
        "    tmp = rh.T/norm\n",
        "    rh = tmp.T\n",
        "    return pose, face, lh, rh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHaK61Ljd2lV"
      },
      "outputs": [],
      "source": [
        "def normalize_zscore(pose, face, lh, rh):\n",
        "       \n",
        "    m = pose.mean(axis=0)\n",
        "    std  = pose.std(axis=0) + 1e-7\n",
        "    pose = (pose - m)/std\n",
        "    \n",
        "    # print(pose.shape,m.shape,std.shape)\n",
        "    \n",
        "    m = face.mean(axis=0)\n",
        "    std  = face.std(axis=0) + 1e-7\n",
        "    face = (face - m)/std\n",
        "    \n",
        "    m = lh.mean(axis=0)\n",
        "    std  = lh.std(axis=0) + 1e-7\n",
        "    lh = (lh - m)/std\n",
        "    \n",
        "    m = rh.mean(axis=0)\n",
        "    std  = rh.std(axis=0) + 1e-7\n",
        "    rh = (rh - m)/std\n",
        "    \n",
        "    return pose, face, lh, rh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xg6MW6m0d2lW"
      },
      "outputs": [],
      "source": [
        "def extract_keypoints(results):\n",
        "\n",
        "    pose = np.array([[res.x, res.y,res.z] for res in results.pose_landmarks.landmark]) if results.pose_landmarks else np.zeros(33*3)\n",
        "    face = np.array([[res.x, res.y,res.z] for res in results.face_landmarks.landmark]) if results.face_landmarks else np.zeros(468*3)\n",
        "    lh = np.array([[res.x, res.y,res.z] for res in results.left_hand_landmarks.landmark]) if results.left_hand_landmarks else np.zeros(21*3)\n",
        "    rh = np.array([[res.x, res.y,res.z] for res in results.right_hand_landmarks.landmark]) if results.right_hand_landmarks else np.zeros(21*3)\n",
        "\n",
        "    pose, face, lh, rh = normalize_zscore(pose, face, lh, rh)\n",
        "\n",
        "    return np.concatenate([pose.flatten(), face.flatten(), lh.flatten(), rh.flatten()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ucnbCs_d2lX"
      },
      "outputs": [],
      "source": [
        "def draw_styled_landmarks(image, results):\n",
        "    # Draw face connections\n",
        "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
        "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
        "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
        "                             ) \n",
        "    # Draw pose connections\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
        "                             ) \n",
        "    # Draw left hand connections\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
        "                             ) \n",
        "    # Draw right hand connections  \n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
        "                             ) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "***"
      ],
      "metadata": {
        "id": "HqMeVlA4a0qv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv9tRo60d2lY"
      },
      "outputs": [],
      "source": [
        "path =\"./traindata/all\"\n",
        "file_list = os.listdir(path)\n",
        "files = file_list\n",
        "files.sort()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZtcUPkMd2lY",
        "outputId": "790c9ce4-d629-49b3-ae9b-09e08a5802dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3200"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w15lPLu1d2lZ",
        "outputId": "cbcb3d2b-9e52-493c-b0c7-73d9b9bdd028"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./traindata/all/001_001_001.mp4', './traindata/all/001_001_002.mp4')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "files = [path+\"/\"+f for f in files]# \n",
        "files[0],files[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TBcFTJLd2lZ"
      },
      "outputs": [],
      "source": [
        "def videoProc(path, c=1,skip=5, o=False):\n",
        "    \"###\"\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    success = True\n",
        "    \n",
        "    framecount = 35\n",
        "\n",
        "    fnum = 0\n",
        "    v = []\n",
        "    \n",
        "    fpsCounter = c\n",
        "\n",
        "    for i in range(skip):\n",
        "        success, frame = cap.read()\n",
        "\n",
        "    while success:     \n",
        "        success, frame = cap.read()\n",
        "        \n",
        "        if fpsCounter==0:\n",
        "            fpsCounter=c\n",
        "        else:\n",
        "            fpsCounter-=1           \n",
        "            continue\n",
        "        if fnum>=framecount:\n",
        "            break\n",
        "\n",
        "        \n",
        "        if success:  \n",
        "            # frame = cv2.resize(frame, (1920,1080), interpolation = cv2.INTER_AREA)\n",
        "            results = mediapipe_detection(frame, holistic)\n",
        "\n",
        "            eres = extract_keypoints(results)\n",
        "            tmp = np.reshape(eres, (1,-1))\n",
        "            v.append(tmp)\n",
        "\n",
        "            fnum += 1\n",
        "            if o:\n",
        "                draw_styled_landmarks(frame, results)\n",
        "                plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "    v = np.reshape(v,(fnum,-1)) if fnum >0 else[]\n",
        "    \n",
        "  \n",
        "    if fnum<framecount and fnum>0:\n",
        "        tmp = np.zeros((framecount-fnum,1629))\n",
        "        v = np.concatenate((v, tmp), axis=0) \n",
        "\n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKzqJ4Bgd2la",
        "outputId": "07672b31-eb21-456d-a116-30c589a65692"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35, 1629)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "v= videoProc(files[256],c=2,o=0)\n",
        "v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4mWhWrRd2la",
        "outputId": "07c402bb-6a11-4b3f-d392-70242d3e0ef5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.849824438815544,\n",
              " -2.3883717377619633,\n",
              " 0.9605423126557638,\n",
              " 2.093680252700111e-16)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "v[34].max(),v[29].min(),v[24].std(),v[24].mean()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "ZUfBS7LWd2lb"
      },
      "source": [
        "s=0\n",
        "for i in range(400,800,5):\n",
        "    v = videoProc(files[i],c=1)\n",
        "    print(i,v.shape[0])\n",
        "    s+=v.shape[0]\n",
        "s/42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsEY286Wd2lc"
      },
      "outputs": [],
      "source": [
        "l=0\n",
        "vids = []\n",
        "labels = []\n",
        "files_ = files[2200:3200]\n",
        "for f in files_:\n",
        "    v = videoProc(f,c=2)\n",
        "    vids.append(v)\n",
        "    label = f.split('/')[-1].split('_')[0] \n",
        "    labels.append(label)\n",
        "    print(l)\n",
        "    l+=1\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp8h7MPNd2ld"
      },
      "outputs": [],
      "source": [
        "labels = [int(l)-1 for l in labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGTAoC0Ad2le"
      },
      "outputs": [],
      "source": [
        "vids = np.array(vids)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcnBGDfAd2le",
        "outputId": "61bc539a-f5df-4753-abe8-a28ece543999"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000,), (1000, 35, 1629))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "labels.shape,vids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz0ntSFOd2le"
      },
      "outputs": [],
      "source": [
        "np.save(\"./vids_3.npy\",vids)\n",
        "np.save(\"./labels_3.npy\",labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "***"
      ],
      "metadata": {
        "id": "G2JySTKVa81H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_oz21sVd2lf"
      },
      "outputs": [],
      "source": [
        "vids1 = np.load(\"./traindata/vids_1.npy\")\n",
        "labels1 = np.load(\"./traindata//labels_1.npy\")\n",
        "\n",
        "vids2 = np.load(\"./traindata//vids_2.npy\")\n",
        "labels2 = np.load(\"./traindata//labels_2.npy\")\n",
        "\n",
        "vids3 = np.load(\"./traindata//vids_3.npy\")\n",
        "labels3 = np.load(\"./traindata//labels_3.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vids = np.concatenate([vids1,vids2,vids3],axis=0)\n",
        "labels = np.concatenate([labels1,labels2,labels3],axis=0)"
      ],
      "metadata": {
        "id": "yTvbkwpDAOUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vids.shape,labels.shape,labels.min(),labels.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkhm91HY47M1",
        "outputId": "8533c7b9-e0f1-4349-be27-e225b03ca039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3200, 35, 1629), (3200,), 0, 63)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92DkAco-d2lf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "536189fb-5456-4d6e-cb45-c79f6041ac02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2720, 35, 1629), (2720,))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_train, X_dev, y_train, y_dev = train_test_split(vids, labels, test_size = 0.15,shuffle=True,random_state=13)\n",
        "X_train.shape,y_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del vids\n",
        "del labels"
      ],
      "metadata": {
        "id": "i5PqiZQDm0jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfAVTKlrd2lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2bf6d50-359e-4488-d547-4e13b36c78b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-3.0678591483563817, 3.6039564378088675, (35, 1629))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "X_train[3].min(),X_train[3].max(),X_train[3].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HNPMiUud2lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a066b8-c0d9-4707-b9ea-b8564ea6dc4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0, 29, 33, 37, 54, 55, 48, 15,  3,  6]), 0, 63, (2720,))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "y_train[0:10],y_train.min(),y_train.max(),y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7q9lb73d2lh"
      },
      "outputs": [],
      "source": [
        "model_lstm_1 = Sequential([\n",
        "\n",
        "tf.keras.Input(shape=(35,1629),),\n",
        "    \n",
        "LSTM(64, return_sequences=True, activation='tanh'),\n",
        "Dropout(0.2),\n",
        "LSTM(128, return_sequences=True, activation='tanh'),\n",
        "Dropout(0.2),\n",
        "LSTM(256, return_sequences=False, activation='tanh'),\n",
        "\n",
        "# Bidirectional(GRU(64, return_sequences=True, activation='tanh')),\n",
        "# Bidirectional(GRU(256, return_sequences=True, activation='tanh')),\n",
        "# Bidirectional(GRU(128, return_sequences=False, activation='tanh')),\n",
        "\n",
        "\n",
        "BatchNormalization(),\n",
        "Dropout(0.4),\n",
        "\n",
        "\n",
        "\n",
        "Dense(256, activation='linear',kernel_regularizer=tf.keras.regularizers.L1L2(0.01,1)),  \n",
        "BatchNormalization(),#axis=-1,center=True,scale=True,\n",
        "ReLU(), \n",
        "\n",
        "Dense(128, activation='linear',kernel_regularizer=tf.keras.regularizers.L1L2(0.01,1)),  \n",
        "BatchNormalization(),#axis=-1,center=True,scale=True,\n",
        "ReLU(), \n",
        "\n",
        "\n",
        "Dense(64, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkM404Fad2lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b1c2228-a438-40be-dee5-8199c4773c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 35, 64)            433664    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 35, 64)            0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 35, 128)           98816     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 35, 128)           0         \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 256)               394240    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 256)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,036,224\n",
            "Trainable params: 1,034,944\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_lstm_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2K4MECAd2lh"
      },
      "outputs": [],
      "source": [
        "model_lstm_1.compile(tf.keras.optimizers.Adam(learning_rate=1e-3,beta_1=0.9,beta_2=0.999,epsilon=1e-07,)\n",
        "        ,loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "            ,metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrJXaEhld2li",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48243e41-d172-466a-d985-f7ad2ea6d28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/256\n",
            "22/22 [==============================] - 11s 34ms/step - loss: 380.3568 - accuracy: 0.0441\n",
            "Epoch 2/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 204.9093 - accuracy: 0.1261\n",
            "Epoch 3/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 104.6230 - accuracy: 0.2474\n",
            "Epoch 4/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 51.1315 - accuracy: 0.4437\n",
            "Epoch 5/256\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 24.1011 - accuracy: 0.6004\n",
            "Epoch 6/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 11.1571 - accuracy: 0.7287\n",
            "Epoch 7/256\n",
            "22/22 [==============================] - 1s 44ms/step - loss: 5.4658 - accuracy: 0.7879\n",
            "Epoch 8/256\n",
            "22/22 [==============================] - 1s 52ms/step - loss: 3.2975 - accuracy: 0.8202\n",
            "Epoch 9/256\n",
            "22/22 [==============================] - 2s 69ms/step - loss: 2.5424 - accuracy: 0.8401\n",
            "Epoch 10/256\n",
            "22/22 [==============================] - 1s 61ms/step - loss: 2.1869 - accuracy: 0.8471\n",
            "Epoch 11/256\n",
            "22/22 [==============================] - 1s 54ms/step - loss: 2.1229 - accuracy: 0.8482\n",
            "Epoch 12/256\n",
            "22/22 [==============================] - 1s 51ms/step - loss: 1.9982 - accuracy: 0.8647\n",
            "Epoch 13/256\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 1.8334 - accuracy: 0.8768\n",
            "Epoch 14/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.7602 - accuracy: 0.9026\n",
            "Epoch 15/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.7746 - accuracy: 0.9059\n",
            "Epoch 16/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.7712 - accuracy: 0.9007\n",
            "Epoch 17/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.6980 - accuracy: 0.9000\n",
            "Epoch 18/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.4960 - accuracy: 0.9305\n",
            "Epoch 19/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.7581 - accuracy: 0.9070\n",
            "Epoch 20/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.4673 - accuracy: 0.9423\n",
            "Epoch 21/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.4959 - accuracy: 0.9309\n",
            "Epoch 22/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 1.4824 - accuracy: 0.9379\n",
            "Epoch 23/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.6564 - accuracy: 0.9187\n",
            "Epoch 24/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.6518 - accuracy: 0.9261\n",
            "Epoch 25/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.4825 - accuracy: 0.9397\n",
            "Epoch 26/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.4173 - accuracy: 0.9390\n",
            "Epoch 27/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.7007 - accuracy: 0.9368\n",
            "Epoch 28/256\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 1.4970 - accuracy: 0.9390\n",
            "Epoch 29/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.2307 - accuracy: 0.9640\n",
            "Epoch 30/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.4160 - accuracy: 0.9426\n",
            "Epoch 31/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.2524 - accuracy: 0.9518\n",
            "Epoch 32/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.6190 - accuracy: 0.9276\n",
            "Epoch 33/256\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 2.0633 - accuracy: 0.9085\n",
            "Epoch 34/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.7375 - accuracy: 0.9316\n",
            "Epoch 35/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.2934 - accuracy: 0.9654\n",
            "Epoch 36/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.4013 - accuracy: 0.9445\n",
            "Epoch 37/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.6934 - accuracy: 0.9426\n",
            "Epoch 38/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.2466 - accuracy: 0.9632\n",
            "Epoch 39/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.1755 - accuracy: 0.9721\n",
            "Epoch 40/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.0180 - accuracy: 0.9721\n",
            "Epoch 41/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.2769 - accuracy: 0.9463\n",
            "Epoch 42/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.2679 - accuracy: 0.9654\n",
            "Epoch 43/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.1656 - accuracy: 0.9548\n",
            "Epoch 44/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.7787 - accuracy: 0.9228\n",
            "Epoch 45/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.5832 - accuracy: 0.9460\n",
            "Epoch 46/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.4356 - accuracy: 0.9533\n",
            "Epoch 47/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.2873 - accuracy: 0.9610\n",
            "Epoch 48/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 2.0119 - accuracy: 0.9239\n",
            "Epoch 49/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.3036 - accuracy: 0.9710\n",
            "Epoch 50/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.7969 - accuracy: 0.9871\n",
            "Epoch 51/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.7141 - accuracy: 0.9801\n",
            "Epoch 52/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.9274 - accuracy: 0.9618\n",
            "Epoch 53/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.9060 - accuracy: 0.9801\n",
            "Epoch 54/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.0623 - accuracy: 0.9636\n",
            "Epoch 55/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.0094 - accuracy: 0.9768\n",
            "Epoch 56/256\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 1.1224 - accuracy: 0.9699\n",
            "Epoch 57/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.8006 - accuracy: 0.9846\n",
            "Epoch 58/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.7240 - accuracy: 0.9801\n",
            "Epoch 59/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.0214 - accuracy: 0.9643\n",
            "Epoch 60/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.2292 - accuracy: 0.9408\n",
            "Epoch 61/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.6944 - accuracy: 0.9379\n",
            "Epoch 62/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.3287 - accuracy: 0.9452\n",
            "Epoch 63/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.0015 - accuracy: 0.9632\n",
            "Epoch 64/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.2013 - accuracy: 0.9548\n",
            "Epoch 65/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.1483 - accuracy: 0.9603\n",
            "Epoch 66/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.1073 - accuracy: 0.9636\n",
            "Epoch 67/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 1.3902 - accuracy: 0.9695\n",
            "Epoch 68/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.7903 - accuracy: 0.9838\n",
            "Epoch 69/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.8098 - accuracy: 0.9864\n",
            "Epoch 70/256\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.6403 - accuracy: 0.9875\n",
            "Epoch 71/256\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.5743 - accuracy: 0.9901\n",
            "Epoch 72/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.9707 - accuracy: 0.9625\n",
            "Epoch 73/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.0909 - accuracy: 0.9662\n",
            "Epoch 74/256\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.9370 - accuracy: 0.9761\n",
            "Epoch 75/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.8542 - accuracy: 0.9790\n",
            "Epoch 76/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.8927 - accuracy: 0.9735\n",
            "Epoch 77/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.6192 - accuracy: 0.9934\n",
            "Epoch 78/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5261 - accuracy: 0.9864\n",
            "Epoch 79/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.9584 - accuracy: 0.9607\n",
            "Epoch 80/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.9556 - accuracy: 0.9706\n",
            "Epoch 81/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.0103 - accuracy: 0.9717\n",
            "Epoch 82/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.4767 - accuracy: 0.9033\n",
            "Epoch 83/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.2849 - accuracy: 0.9563\n",
            "Epoch 84/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.3223 - accuracy: 0.9504\n",
            "Epoch 85/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.1176 - accuracy: 0.9585\n",
            "Epoch 86/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.0238 - accuracy: 0.9662\n",
            "Epoch 87/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6784 - accuracy: 0.9890\n",
            "Epoch 88/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5383 - accuracy: 0.9901\n",
            "Epoch 89/256\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.5752 - accuracy: 0.9934\n",
            "Epoch 90/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.3850 - accuracy: 0.9908\n",
            "Epoch 91/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.5292 - accuracy: 0.9890\n",
            "Epoch 92/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.7027 - accuracy: 0.9864\n",
            "Epoch 93/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.6053 - accuracy: 0.9794\n",
            "Epoch 94/256\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.7094 - accuracy: 0.9827\n",
            "Epoch 95/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.7148 - accuracy: 0.9676\n",
            "Epoch 96/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 1.1211 - accuracy: 0.9426\n",
            "Epoch 97/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.2194 - accuracy: 0.9474\n",
            "Epoch 98/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.0246 - accuracy: 0.9588\n",
            "Epoch 99/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.0382 - accuracy: 0.9533\n",
            "Epoch 100/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.2098 - accuracy: 0.9471\n",
            "Epoch 101/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.8114 - accuracy: 0.9776\n",
            "Epoch 102/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.0176 - accuracy: 0.9544\n",
            "Epoch 103/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.1613 - accuracy: 0.9621\n",
            "Epoch 104/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.7945 - accuracy: 0.9864\n",
            "Epoch 105/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4097 - accuracy: 0.9974\n",
            "Epoch 106/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3781 - accuracy: 0.9915\n",
            "Epoch 107/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4990 - accuracy: 0.9930\n",
            "Epoch 108/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4096 - accuracy: 0.9949\n",
            "Epoch 109/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.3920 - accuracy: 0.9956\n",
            "Epoch 110/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.4466 - accuracy: 0.9897\n",
            "Epoch 111/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.5336 - accuracy: 0.9919\n",
            "Epoch 112/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.5099 - accuracy: 0.9945\n",
            "Epoch 113/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.4362 - accuracy: 0.9897\n",
            "Epoch 114/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.6139 - accuracy: 0.9915\n",
            "Epoch 115/256\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.6247 - accuracy: 0.9732\n",
            "Epoch 116/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.0742 - accuracy: 0.9415\n",
            "Epoch 117/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.6913 - accuracy: 0.9107\n",
            "Epoch 118/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.3535 - accuracy: 0.9574\n",
            "Epoch 119/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.3835 - accuracy: 0.9331\n",
            "Epoch 120/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.2776 - accuracy: 0.9739\n",
            "Epoch 121/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.7855 - accuracy: 0.9820\n",
            "Epoch 122/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.2695 - accuracy: 0.9717\n",
            "Epoch 123/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.9821 - accuracy: 0.9838\n",
            "Epoch 124/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.5817 - accuracy: 0.9901\n",
            "Epoch 125/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5289 - accuracy: 0.9934\n",
            "Epoch 126/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.8786 - accuracy: 0.9768\n",
            "Epoch 127/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.4065 - accuracy: 0.9254\n",
            "Epoch 128/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.5571 - accuracy: 0.9449\n",
            "Epoch 129/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.1345 - accuracy: 0.9662\n",
            "Epoch 130/256\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.9022 - accuracy: 0.9743\n",
            "Epoch 131/256\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 1.1482 - accuracy: 0.9585\n",
            "Epoch 132/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.2373 - accuracy: 0.9588\n",
            "Epoch 133/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.9702 - accuracy: 0.9761\n",
            "Epoch 134/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.9853 - accuracy: 0.9614\n",
            "Epoch 135/256\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 1.1330 - accuracy: 0.9504\n",
            "Epoch 136/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.0374 - accuracy: 0.9746\n",
            "Epoch 137/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.7813 - accuracy: 0.9772\n",
            "Epoch 138/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.9626 - accuracy: 0.9812\n",
            "Epoch 139/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.7184 - accuracy: 0.9871\n",
            "Epoch 140/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4761 - accuracy: 0.9919\n",
            "Epoch 141/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5333 - accuracy: 0.9886\n",
            "Epoch 142/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4513 - accuracy: 0.9941\n",
            "Epoch 143/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3199 - accuracy: 0.9982\n",
            "Epoch 144/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3299 - accuracy: 0.9915\n",
            "Epoch 145/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4281 - accuracy: 0.9912\n",
            "Epoch 146/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.4705 - accuracy: 0.9849\n",
            "Epoch 147/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.8592 - accuracy: 0.9662\n",
            "Epoch 148/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.8048 - accuracy: 0.9783\n",
            "Epoch 149/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.8379 - accuracy: 0.9654\n",
            "Epoch 150/256\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.8040 - accuracy: 0.9827\n",
            "Epoch 151/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.6069 - accuracy: 0.9871\n",
            "Epoch 152/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.5053 - accuracy: 0.9934\n",
            "Epoch 153/256\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.9554 - accuracy: 0.9761\n",
            "Epoch 154/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.0750 - accuracy: 0.9743\n",
            "Epoch 155/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 1.4079 - accuracy: 0.9614\n",
            "Epoch 156/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.1338 - accuracy: 0.9794\n",
            "Epoch 157/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.8296 - accuracy: 0.9838\n",
            "Epoch 158/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.8863 - accuracy: 0.9820\n",
            "Epoch 159/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.6889 - accuracy: 0.9879\n",
            "Epoch 160/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.6309 - accuracy: 0.9835\n",
            "Epoch 161/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.9982 - accuracy: 0.9651\n",
            "Epoch 162/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.9032 - accuracy: 0.9702\n",
            "Epoch 163/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 1.3772 - accuracy: 0.9463\n",
            "Epoch 164/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.9494 - accuracy: 0.9871\n",
            "Epoch 165/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.4884 - accuracy: 0.9934\n",
            "Epoch 166/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6978 - accuracy: 0.9838\n",
            "Epoch 167/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5519 - accuracy: 0.9930\n",
            "Epoch 168/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5890 - accuracy: 0.9798\n",
            "Epoch 169/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.8898 - accuracy: 0.9665\n",
            "Epoch 170/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.9443 - accuracy: 0.9618\n",
            "Epoch 171/256\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 1.3690 - accuracy: 0.9504\n",
            "Epoch 172/256\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 1.1668 - accuracy: 0.9654\n",
            "Epoch 173/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 1.0207 - accuracy: 0.9757\n",
            "Epoch 174/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.8033 - accuracy: 0.9882\n",
            "Epoch 175/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 1.3905 - accuracy: 0.9518\n",
            "Epoch 176/256\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 1.1560 - accuracy: 0.9735\n",
            "Epoch 177/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.7280 - accuracy: 0.9923\n",
            "Epoch 178/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3983 - accuracy: 0.9960\n",
            "Epoch 179/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4899 - accuracy: 0.9890\n",
            "Epoch 180/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5741 - accuracy: 0.9930\n",
            "Epoch 181/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4989 - accuracy: 0.9941\n",
            "Epoch 182/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5183 - accuracy: 0.9952\n",
            "Epoch 183/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3282 - accuracy: 0.9974\n",
            "Epoch 184/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4090 - accuracy: 0.9985\n",
            "Epoch 185/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.2789 - accuracy: 1.0000\n",
            "Epoch 186/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.2290 - accuracy: 0.9978\n",
            "Epoch 187/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3666 - accuracy: 0.9967\n",
            "Epoch 188/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.2713 - accuracy: 0.9985\n",
            "Epoch 189/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3224 - accuracy: 0.9960\n",
            "Epoch 190/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3476 - accuracy: 0.9985\n",
            "Epoch 191/256\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.1934 - accuracy: 0.9993\n",
            "Epoch 192/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.2163 - accuracy: 0.9982\n",
            "Epoch 193/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.3016 - accuracy: 0.9934\n",
            "Epoch 194/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.2240 - accuracy: 0.9669\n",
            "Epoch 195/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.2688 - accuracy: 0.9684\n",
            "Epoch 196/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 1.2087 - accuracy: 0.9438\n",
            "Epoch 197/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.6466 - accuracy: 0.9077\n",
            "Epoch 198/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 2.0661 - accuracy: 0.8864\n",
            "Epoch 199/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 2.0740 - accuracy: 0.8886\n",
            "Epoch 200/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 1.4659 - accuracy: 0.9574\n",
            "Epoch 201/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.7979 - accuracy: 0.9853\n",
            "Epoch 202/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.2765 - accuracy: 0.9599\n",
            "Epoch 203/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.9058 - accuracy: 0.9853\n",
            "Epoch 204/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5339 - accuracy: 0.9941\n",
            "Epoch 205/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3597 - accuracy: 0.9963\n",
            "Epoch 206/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3266 - accuracy: 0.9960\n",
            "Epoch 207/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3003 - accuracy: 0.9971\n",
            "Epoch 208/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3223 - accuracy: 0.9930\n",
            "Epoch 209/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4295 - accuracy: 0.9952\n",
            "Epoch 210/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4087 - accuracy: 0.9941\n",
            "Epoch 211/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3772 - accuracy: 0.9926\n",
            "Epoch 212/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.4323 - accuracy: 0.9974\n",
            "Epoch 213/256\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.3042 - accuracy: 0.9974\n",
            "Epoch 214/256\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.2335 - accuracy: 0.9982\n",
            "Epoch 215/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.3448 - accuracy: 0.9937\n",
            "Epoch 216/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.3975 - accuracy: 0.9926\n",
            "Epoch 217/256\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.3146 - accuracy: 0.9967\n",
            "Epoch 218/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.3357 - accuracy: 0.9982\n",
            "Epoch 219/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.2385 - accuracy: 0.9985\n",
            "Epoch 220/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.2130 - accuracy: 0.9956\n",
            "Epoch 221/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.4422 - accuracy: 0.9908\n",
            "Epoch 222/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.7132 - accuracy: 0.9820\n",
            "Epoch 223/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.6469 - accuracy: 0.9787\n",
            "Epoch 224/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.7906 - accuracy: 0.9596\n",
            "Epoch 225/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.9611 - accuracy: 0.9544\n",
            "Epoch 226/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.9116 - accuracy: 0.9710\n",
            "Epoch 227/256\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.6592 - accuracy: 0.9805\n",
            "Epoch 228/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.8034 - accuracy: 0.9732\n",
            "Epoch 229/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.0538 - accuracy: 0.9467\n",
            "Epoch 230/256\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 1.2148 - accuracy: 0.9540\n",
            "Epoch 231/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 1.1202 - accuracy: 0.9555\n",
            "Epoch 232/256\n",
            "22/22 [==============================] - 1s 39ms/step - loss: 0.9095 - accuracy: 0.9640\n",
            "Epoch 233/256\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.7036 - accuracy: 0.9812\n",
            "Epoch 234/256\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.5647 - accuracy: 0.9809\n",
            "Epoch 235/256\n",
            "22/22 [==============================] - 1s 42ms/step - loss: 0.8690 - accuracy: 0.9713\n",
            "Epoch 236/256\n",
            "22/22 [==============================] - 1s 42ms/step - loss: 0.7685 - accuracy: 0.9831\n",
            "Epoch 237/256\n",
            "22/22 [==============================] - 1s 40ms/step - loss: 0.5627 - accuracy: 0.9868\n",
            "Epoch 238/256\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.4864 - accuracy: 0.9904\n",
            "Epoch 239/256\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.6097 - accuracy: 0.9893\n",
            "Epoch 240/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.7648 - accuracy: 0.9699\n",
            "Epoch 241/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6629 - accuracy: 0.9857\n",
            "Epoch 242/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.8302 - accuracy: 0.9739\n",
            "Epoch 243/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.6580 - accuracy: 0.9930\n",
            "Epoch 244/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.3727 - accuracy: 0.9949\n",
            "Epoch 245/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.5388 - accuracy: 0.9824\n",
            "Epoch 246/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.8178 - accuracy: 0.9563\n",
            "Epoch 247/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.1432 - accuracy: 0.9202\n",
            "Epoch 248/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.8869 - accuracy: 0.8768\n",
            "Epoch 249/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 1.3829 - accuracy: 0.9585\n",
            "Epoch 250/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.8149 - accuracy: 0.9783\n",
            "Epoch 251/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.9563 - accuracy: 0.9772\n",
            "Epoch 252/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.9368 - accuracy: 0.9746\n",
            "Epoch 253/256\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.8818 - accuracy: 0.9871\n",
            "Epoch 254/256\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.6248 - accuracy: 0.9930\n",
            "Epoch 255/256\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.7021 - accuracy: 0.9853\n",
            "Epoch 256/256\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.5464 - accuracy: 0.9971\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf3636d670>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model_lstm_1.fit(X_train, y_train, epochs=256, batch_size=128, )#batch_size=64 ,#validation_data=(X_dev, y_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q-Ll2P0d2li"
      },
      "outputs": [],
      "source": [
        "model_lstm_1.compile(tf.keras.optimizers.Adam(learning_rate=1e-4,beta_1=0.9,beta_2=0.999,epsilon=1e-07,)\n",
        "        ,loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "            ,metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvaovqJfd2lj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73cd5328-b81b-4993-8474-df96cdee6d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/128\n",
            "22/22 [==============================] - 10s 34ms/step - loss: 0.2304 - accuracy: 0.9982\n",
            "Epoch 2/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.1348 - accuracy: 1.0000\n",
            "Epoch 3/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.1026 - accuracy: 0.9996\n",
            "Epoch 4/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0862 - accuracy: 1.0000\n",
            "Epoch 5/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0771 - accuracy: 1.0000\n",
            "Epoch 6/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0730 - accuracy: 1.0000\n",
            "Epoch 7/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0754 - accuracy: 0.9993\n",
            "Epoch 8/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0719 - accuracy: 1.0000\n",
            "Epoch 9/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0680 - accuracy: 1.0000\n",
            "Epoch 10/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0679 - accuracy: 0.9996\n",
            "Epoch 11/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0699 - accuracy: 1.0000\n",
            "Epoch 12/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 13/128\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.0761 - accuracy: 0.9967\n",
            "Epoch 14/128\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.0858 - accuracy: 0.9993\n",
            "Epoch 15/128\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.0761 - accuracy: 1.0000\n",
            "Epoch 16/128\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.0671 - accuracy: 1.0000\n",
            "Epoch 17/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0672 - accuracy: 0.9996\n",
            "Epoch 18/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0680 - accuracy: 0.9993\n",
            "Epoch 19/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0718 - accuracy: 0.9985\n",
            "Epoch 20/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0719 - accuracy: 1.0000\n",
            "Epoch 21/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0640 - accuracy: 1.0000\n",
            "Epoch 22/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0616 - accuracy: 1.0000\n",
            "Epoch 23/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0611 - accuracy: 0.9993\n",
            "Epoch 24/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0661 - accuracy: 1.0000\n",
            "Epoch 25/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0690 - accuracy: 1.0000\n",
            "Epoch 26/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0635 - accuracy: 1.0000\n",
            "Epoch 27/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0611 - accuracy: 1.0000\n",
            "Epoch 28/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0609 - accuracy: 1.0000\n",
            "Epoch 29/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0605 - accuracy: 1.0000\n",
            "Epoch 30/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0591 - accuracy: 1.0000\n",
            "Epoch 31/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0590 - accuracy: 1.0000\n",
            "Epoch 32/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0611 - accuracy: 0.9996\n",
            "Epoch 33/128\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.0596 - accuracy: 1.0000\n",
            "Epoch 34/128\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.0581 - accuracy: 1.0000\n",
            "Epoch 35/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0592 - accuracy: 1.0000\n",
            "Epoch 36/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0647 - accuracy: 0.9993\n",
            "Epoch 37/128\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.0669 - accuracy: 1.0000\n",
            "Epoch 38/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0600 - accuracy: 1.0000\n",
            "Epoch 39/128\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.0572 - accuracy: 1.0000\n",
            "Epoch 40/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0558 - accuracy: 1.0000\n",
            "Epoch 41/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0591 - accuracy: 0.9996\n",
            "Epoch 42/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0620 - accuracy: 0.9996\n",
            "Epoch 43/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0591 - accuracy: 0.9996\n",
            "Epoch 44/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0615 - accuracy: 0.9996\n",
            "Epoch 45/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0569 - accuracy: 1.0000\n",
            "Epoch 46/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0561 - accuracy: 0.9996\n",
            "Epoch 47/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0559 - accuracy: 1.0000\n",
            "Epoch 48/128\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.0547 - accuracy: 1.0000\n",
            "Epoch 49/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0535 - accuracy: 1.0000\n",
            "Epoch 50/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0547 - accuracy: 1.0000\n",
            "Epoch 51/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0534 - accuracy: 1.0000\n",
            "Epoch 52/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0536 - accuracy: 1.0000\n",
            "Epoch 53/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0540 - accuracy: 1.0000\n",
            "Epoch 54/128\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.0537 - accuracy: 1.0000\n",
            "Epoch 55/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0525 - accuracy: 1.0000\n",
            "Epoch 56/128\n",
            "22/22 [==============================] - 1s 38ms/step - loss: 0.0524 - accuracy: 1.0000\n",
            "Epoch 57/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0525 - accuracy: 1.0000\n",
            "Epoch 58/128\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.0519 - accuracy: 1.0000\n",
            "Epoch 59/128\n",
            "22/22 [==============================] - 1s 32ms/step - loss: 0.0516 - accuracy: 1.0000\n",
            "Epoch 60/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0526 - accuracy: 1.0000\n",
            "Epoch 61/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0515 - accuracy: 1.0000\n",
            "Epoch 62/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0520 - accuracy: 1.0000\n",
            "Epoch 63/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0516 - accuracy: 1.0000\n",
            "Epoch 64/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0531 - accuracy: 1.0000\n",
            "Epoch 65/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0509 - accuracy: 1.0000\n",
            "Epoch 66/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0507 - accuracy: 1.0000\n",
            "Epoch 67/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0504 - accuracy: 1.0000\n",
            "Epoch 68/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0505 - accuracy: 1.0000\n",
            "Epoch 69/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0502 - accuracy: 1.0000\n",
            "Epoch 70/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0561 - accuracy: 1.0000\n",
            "Epoch 71/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0577 - accuracy: 0.9993\n",
            "Epoch 72/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0742 - accuracy: 0.9993\n",
            "Epoch 73/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0660 - accuracy: 1.0000\n",
            "Epoch 74/128\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.0547 - accuracy: 1.0000\n",
            "Epoch 75/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0510 - accuracy: 1.0000\n",
            "Epoch 76/128\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.0496 - accuracy: 1.0000\n",
            "Epoch 77/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0513 - accuracy: 1.0000\n",
            "Epoch 78/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0582 - accuracy: 0.9993\n",
            "Epoch 79/128\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.0652 - accuracy: 1.0000\n",
            "Epoch 80/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0551 - accuracy: 1.0000\n",
            "Epoch 81/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0558 - accuracy: 0.9993\n",
            "Epoch 82/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0806 - accuracy: 0.9993\n",
            "Epoch 83/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0742 - accuracy: 0.9996\n",
            "Epoch 84/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0608 - accuracy: 1.0000\n",
            "Epoch 85/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0523 - accuracy: 1.0000\n",
            "Epoch 86/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0496 - accuracy: 1.0000\n",
            "Epoch 87/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0480 - accuracy: 1.0000\n",
            "Epoch 88/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0470 - accuracy: 1.0000\n",
            "Epoch 89/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0481 - accuracy: 1.0000\n",
            "Epoch 90/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0490 - accuracy: 1.0000\n",
            "Epoch 91/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0501 - accuracy: 0.9993\n",
            "Epoch 92/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0766 - accuracy: 1.0000\n",
            "Epoch 93/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0781 - accuracy: 0.9993\n",
            "Epoch 94/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0721 - accuracy: 1.0000\n",
            "Epoch 95/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0599 - accuracy: 1.0000\n",
            "Epoch 96/128\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.0521 - accuracy: 1.0000\n",
            "Epoch 97/128\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.0489 - accuracy: 1.0000\n",
            "Epoch 98/128\n",
            "22/22 [==============================] - 1s 36ms/step - loss: 0.0554 - accuracy: 0.9989\n",
            "Epoch 99/128\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.0865 - accuracy: 0.9952\n",
            "Epoch 100/128\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.0924 - accuracy: 0.9982\n",
            "Epoch 101/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0776 - accuracy: 0.9993\n",
            "Epoch 102/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0664 - accuracy: 1.0000\n",
            "Epoch 103/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0551 - accuracy: 1.0000\n",
            "Epoch 104/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0492 - accuracy: 1.0000\n",
            "Epoch 105/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0468 - accuracy: 1.0000\n",
            "Epoch 106/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0464 - accuracy: 1.0000\n",
            "Epoch 107/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 108/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0460 - accuracy: 1.0000\n",
            "Epoch 109/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0449 - accuracy: 1.0000\n",
            "Epoch 110/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 111/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0447 - accuracy: 1.0000\n",
            "Epoch 112/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0444 - accuracy: 1.0000\n",
            "Epoch 113/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0455 - accuracy: 1.0000\n",
            "Epoch 114/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0476 - accuracy: 1.0000\n",
            "Epoch 115/128\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.0456 - accuracy: 1.0000\n",
            "Epoch 116/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0453 - accuracy: 1.0000\n",
            "Epoch 117/128\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.0445 - accuracy: 1.0000\n",
            "Epoch 118/128\n",
            "22/22 [==============================] - 1s 35ms/step - loss: 0.0444 - accuracy: 1.0000\n",
            "Epoch 119/128\n",
            "22/22 [==============================] - 1s 37ms/step - loss: 0.0446 - accuracy: 1.0000\n",
            "Epoch 120/128\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.0446 - accuracy: 1.0000\n",
            "Epoch 121/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0480 - accuracy: 1.0000\n",
            "Epoch 122/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0458 - accuracy: 1.0000\n",
            "Epoch 123/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0448 - accuracy: 1.0000\n",
            "Epoch 124/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0438 - accuracy: 1.0000\n",
            "Epoch 125/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0439 - accuracy: 1.0000\n",
            "Epoch 126/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0441 - accuracy: 1.0000\n",
            "Epoch 127/128\n",
            "22/22 [==============================] - 1s 30ms/step - loss: 0.0433 - accuracy: 1.0000\n",
            "Epoch 128/128\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.0455 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf1a9a24f0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model_lstm_1.fit(X_train, y_train, epochs=128, batch_size=128,)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "WjpvX_x2d2lj"
      },
      "source": [
        "reconstructed_model = tf.keras.models.load_model(\"./modelArgantine/v6\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn7BhRLnd2lj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da6cd48-0880-441b-ae9d-507704b8b40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 1s 10ms/step - loss: 0.0408 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04075738787651062, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "model_lstm_1.evaluate(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8In9OzFfd2lj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8767f818-0430-4f92-d573-06acaa1d6f1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 9ms/step - loss: 0.0673 - accuracy: 0.9958\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06730152666568756, 0.9958333373069763]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model_lstm_1.evaluate(X_dev, y_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XtJXHhkd2lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a4198b-1fdc-4d79-ee32-6b4296252cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model_lstm_1.save(\"./modelArgantine/v0_1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA6r8PfPd2lk"
      },
      "outputs": [],
      "source": [
        "def videoProc2(path, c=1, skip=0, o=False):\n",
        "    \"###\"\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    success = True\n",
        "    \n",
        "    framecount = 35\n",
        "\n",
        "    fnum = 0\n",
        "    v = []\n",
        "    \n",
        "    fpsCounter = c\n",
        "\n",
        "\n",
        "    while success:     \n",
        "        success, frame = cap.read()\n",
        "        \n",
        "        if fpsCounter==0:\n",
        "            fpsCounter=c\n",
        "        else:\n",
        "            fpsCounter-=1           \n",
        "            continue\n",
        "        \n",
        "        \n",
        "        if success:  \n",
        "            frame = cv2.resize(frame, (1920,1080), interpolation = cv2.INTER_AREA)\n",
        "            results = mediapipe_detection(frame, holistic)\n",
        "\n",
        "            eres = extract_keypoints(results)\n",
        "            tmp = np.reshape(eres, (1,-1))\n",
        "            v.append(tmp)\n",
        "\n",
        "            fnum += 1\n",
        "            if o:\n",
        "                draw_styled_landmarks(frame, results)\n",
        "                plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "    \n",
        "    v = np.reshape(v,(fnum,-1)) if fnum >0 else[]\n",
        "\n",
        "\n",
        "    if fnum > framecount+skip:\n",
        "        # f = int((fnum>framecount)/2)\n",
        "        v = v[skip:framecount+skip]\n",
        "    else:  v[0:framecount]\n",
        "        \n",
        "    if fnum<framecount and fnum>0:\n",
        "        tmp = np.zeros((framecount-fnum,1629))\n",
        "        v = np.concatenate((v, tmp), axis=0) \n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path =\"./traindata/all\"\n",
        "file_list = os.listdir(path)\n",
        "files = file_list\n",
        "files.sort()\n",
        "files = [path+\"/\"+f for f in files]# \n",
        "files[0],files[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxEiRuJBfEyg",
        "outputId": "3c1bb538-c7f1-4b05-f805-f453ac2272f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./traindata/all/001_001_001.mp4', './traindata/all/001_001_002.mp4')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IWymHZNd2lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "013508e8-1fa3-4981-c3c7-cf6a6b55f481"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.967122850833467,\n",
              " 3.967190793425681,\n",
              " 3.9582499032424643,\n",
              " 3.9716401921654456,\n",
              " (35, 1629))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "v = videoProc2(files[512],c=0,skip=8,o=0)#files[123]\n",
        "v[34].max(),v[29].max(),v[24].max(),v[15].max(),v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kizl2IsLd2ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c6a582-b783-4a46-f386-259d9bebe82c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, array([[6.6534440e-06, 9.2004177e-07, 7.8497196e-06, 9.9774676e-05,\n",
              "         1.8294284e-06, 7.0426572e-04, 6.6068409e-05, 2.4150679e-05,\n",
              "         2.7859164e-04, 6.1483202e-06, 9.9753004e-01, 8.5671045e-06,\n",
              "         1.6739761e-05, 4.2467935e-05, 4.0553806e-07, 6.3226551e-05,\n",
              "         1.1462183e-05, 5.3659420e-07, 4.2449232e-05, 7.7958604e-05,\n",
              "         4.4829380e-07, 7.6543131e-08, 3.4410614e-04, 1.4799239e-09,\n",
              "         1.3731545e-08, 1.7967602e-09, 6.9691123e-06, 2.7562690e-09,\n",
              "         1.3686612e-06, 8.1729352e-09, 1.0872761e-05, 3.9033015e-08,\n",
              "         1.3160633e-09, 2.8876062e-05, 4.2772126e-07, 7.2412796e-08,\n",
              "         1.7051432e-06, 1.4672322e-04, 4.0374939e-09, 3.5031039e-08,\n",
              "         2.8967229e-08, 1.6245968e-06, 5.0383750e-07, 7.2494743e-08,\n",
              "         2.4702723e-07, 6.7493957e-08, 4.5755139e-10, 8.9678597e-06,\n",
              "         4.3740888e-06, 7.4908728e-09, 1.2797406e-07, 1.4423752e-07,\n",
              "         2.0365169e-05, 1.7955854e-07, 1.6089983e-07, 2.6609702e-04,\n",
              "         5.5141159e-06, 1.5504748e-04, 1.5486104e-07, 2.3582086e-06,\n",
              "         5.3501090e-08, 4.0034121e-07, 1.6871463e-06, 3.1318713e-08]],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "p=model_lstm_1.predict(np.reshape(v, (1,35,1629)))\n",
        "np.argmax(p),p\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NXiZe7ONgdvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yb4EBVmageB4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a8e62510b8e8983f7396e073327258ed7f98a07d0a71789f266ad6c411666256"
      }
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}